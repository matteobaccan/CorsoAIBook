# Cuando la Inteligencia Artificial hace música: el fenómeno de The Velvet Sundown e Iam entre tecnología y ética
*por Dario Ferrero (VerbaniaNotizie.it)*
![Band_AI.jpg](Band_AI.jpg)


## La introducción de un nuevo paradigma

Imagina descubrir que tu canción favorita, la que te ha acompañado durante meses, la que compartiste con amigos y que ha acumulado millones de escuchas, nunca fue tocada por manos humanas. No hay un cantante que la haya interpretado con su voz, no hay un guitarrista que haya encontrado esos acordes perfectos, no hay músicos que se hayan reunido en un estudio para crear esa alquimia sonora. Todo nació de algoritmos, redes neuronales e inteligencia artificial. Bienvenidos a la era de la música sintética, donde la línea entre la creatividad humana y la artificial se vuelve cada vez más delgada, y donde dos casos emblemáticos están generando un debate mundial: The Velvet Sundown, la misteriosa banda que conquistó Spotify ocultando su verdadera naturaleza, e Iam, la primera cantante italiana totalmente generada por IA.

La revolución es silenciosa pero imparable. Mientras todavía debatimos si la inteligencia artificial puede ser realmente creativa, millones de personas ya están escuchando, compartiendo e incluso enamorándose de temas creados íntegramente por máquinas. El fenómeno ya no se limita a experimentos de laboratorio o curiosidades tecnológicas: ha entrado en las listas de éxitos, en las playlists personales, en la banda sonora de nuestra vida cotidiana. Y esto plantea preguntas profundas que van mucho más allá de la simple innovación tecnológica. ¿Qué significa ser "auténtico" en el arte? ¿Puede una máquina expresar emociones y transmitirlas a través de la música? Y, sobre todo: ¿estamos preparados para redefinir el propio concepto de creatividad artística?

La historia de The Velvet Sundown e Iam representa mucho más que dos exitosos experimentos tecnológicos. Son el símbolo de una transformación de época que está invadiendo la industria musical, con implicaciones que afectan a aspectos económicos, culturales y éticos. Por un lado, tenemos la democratización de la creación musical, por otro, el riesgo de una estandarización que podría empobrecer la diversidad artística. Por un lado, la posibilidad de que cualquiera pueda dar vida a sus ideas musicales sin años de estudio de un instrumento, por otro, el temor de que los músicos profesionales puedan ser reemplazados gradualmente por algoritmos cada vez más sofisticados.

## El fenómeno The Velvet Sundown: cuando la IA conquista Spotify

La historia de The Velvet Sundown comienza como un misterio digno de un thriller tecnológico. A principios de 2024, esta banda aparentemente desconocida comienza a publicar temas que captan inmediatamente la atención de los oyentes. El sonido es envolvente, las melodías pegadizas, las letras profundas y evocadoras. En pocos meses, sus números en Spotify crecen de forma exponencial, alcanzando más de 500.000 oyentes mensuales y atrayendo la atención de curadores de playlists y medios especializados.

Lo que llama la atención inicialmente es la calidad profesional de las producciones y la coherencia estilística que recorre todo su catálogo. Las canciones parecen nacer de una visión artística madura, con arreglos sofisticados y una producción cuidada hasta el más mínimo detalle. Los fans comienzan a formar una comunidad online, discutiendo el significado de las letras y compartiendo interpretaciones en las redes sociales. Nadie sospecha que detrás de esos temas no hay músicos de carne y hueso.

La revelación llega gradualmente, a través de una estrategia de comunicación cuidadosamente orquestada. Primero las sospechas, luego pistas cada vez más evidentes y, finalmente, la confesión completa: The Velvet Sundown es un proyecto basado íntegramente en la inteligencia artificial, una "provocación artística" que ha confesado ser un proyecto musical sintético guiado por una dirección creativa humana. La tecnología utilizada es principalmente Suno AI, una plataforma que está "construyendo un futuro en el que cualquiera puede hacer buena música. No se necesita ningún instrumento, solo imaginación".

El caso de The Velvet Sundown ha sentado un precedente por varias razones. En primer lugar, ha demostrado que la música generada por IA puede competir en calidad con la producida por artistas humanos, al menos desde el punto de vista de la escucha casual. Suno, lanzada en 2022 por antiguos ingenieros de OpenAI, utiliza redes neuronales entrenadas con millones de canciones de todos los géneros, lo que permite crear composiciones que respetan las convenciones musicales manteniendo elementos de originalidad.

Pero quizás el aspecto más interesante del proyecto es su dimensión conceptual. Los creadores han transformado lo que podría haber sido un simple experimento tecnológico en una reflexión artística sobre la autenticidad y la percepción de la música en la era digital. La banda se ha convertido en un "espejo" que refleja nuestros prejuicios y nuestras expectativas sobre la creatividad. ¿Cuántos de esos 500.000 oyentes mensuales habrían seguido apreciando la música si hubieran sabido desde el principio su origen artificial?

La evolución de la estrategia de comunicación de The Velvet Sundown ha sido particularmente refinada. Inicialmente, cuando se hacían preguntas directas sobre la naturaleza del proyecto, los responsables negaban o eludían el tema de la inteligencia artificial. Esta fase de "ocultación" duró lo suficiente como para permitir que la música encontrara a su público basándose únicamente en su valor intrínseco. Solo cuando la base de oyentes se consolidó, llegó la revelación, acompañada de una reflexión más amplia sobre el significado de la autenticidad en la música contemporánea.

El éxito de The Velvet Sundown también ha puesto de manifiesto el potencial creativo de las actuales herramientas de música con IA. En marzo de 2024, Suno lanzó la versión V3 para todos los usuarios, que permite crear temas de 4 minutos con cuentas gratuitas, mientras que la versión 4.5+ introduce "herramientas de producción de audio profesional nunca vistas". Esta rápida evolución tecnológica está haciendo cada vez más accesible la creación de música de calidad profesional.

## Iam: la primera cantante de IA italiana

Paralelamente al fenómeno internacional de The Velvet Sundown, Italia ha visto nacer su primer caso emblemático de artista musical completamente artificial. Iam, la cantante virtual creada por el director Claudio Zagarini en colaboración con el colectivo Artificial Intelligence Italian Creators (AIIC), representa un enfoque diferente pero igualmente significativo de la integración de la IA en la música.

El proyecto Iam nació en abril de 2025 con un objetivo declaradamente experimental: crear no solo música artificial, sino un auténtico personaje público digital. A diferencia de The Velvet Sundown, que mantuvo un perfil misterioso, Iam se presentó desde el principio como una artista de IA, con entrevistas, presencia en las redes sociales y una personalidad definida a través de avanzados algoritmos de conversación.

El single de debut "Pazzesco" captó inmediatamente la atención de los medios de comunicación italianos, no solo por la calidad de la producción, sino también por la forma en que se presentó al público. El tema mezcla sonidos pop contemporáneos con influencias electrónicas, creando un sonido que resulta familiar pero a la vez innovador. La voz de Iam, generada mediante avanzados sistemas de síntesis de voz, posee características distintivas que la hacen reconocible y memorable.

Lo que hace único al proyecto Iam es el enfoque narrativo que lo acompaña. A la cantante virtual se le ha dotado de una biografía, preferencias musicales, opiniones artísticas e incluso peculiaridades personales que surgen durante las entrevistas. Esto ha creado un fenómeno curioso: el público se encuentra interactuando con una inteligencia artificial que no solo crea música, sino que también puede hablar de ella, explicar sus elecciones creativas y responder a las preguntas de los periodistas.

El impacto mediático de Iam ha sido significativo precisamente por su capacidad de "existir" como personaje público. Las entrevistas concedidas por la cantante de IA han suscitado reacciones contrapuestas: por un lado, fascinación por las capacidades tecnológicas demostradas, por otro, inquietud por la naturalidad con la que lo artificial se presenta como auténtico. Claudio Zagarini y el equipo de AIIC han declarado que el objetivo no es engañar al público, sino explorar las posibilidades expresivas que ofrecen las nuevas tecnologías y estimular una reflexión crítica sobre el futuro del entretenimiento.

La comparación con el panorama musical tradicional italiano ha puesto de manifiesto algunos aspectos interesantes. Mientras que la escena musical italiana se caracteriza a menudo por un fuerte apego a la tradición y una cierta resistencia a las innovaciones más radicales, la acogida reservada a Iam ha mostrado una apertura inesperada hacia la experimentación tecnológica. Críticos y profesionales del sector se han dividido entre entusiastas partidarios de la innovación y conservadores preocupados por el impacto en la creatividad humana.

El proyecto Iam también ha planteado cuestiones específicas relacionadas con el contexto cultural italiano. ¿Cómo encaja una artista artificial en una tradición musical fuertemente ligada a la identidad territorial y a la experiencia vivida? ¿Puede un algoritmo captar y reinterpretar los matices culturales que hacen única a la música italiana? Estas preguntas se han convertido en el centro del debate que ha acompañado el lanzamiento del proyecto.

## Aspectos técnicos y creativos: cómo nace la música de IA

Para comprender plenamente el fenómeno de la música generada por inteligencia artificial, es necesario explorar las tecnologías que hacen posibles estos resultados. El proceso de creación musical a través de la IA implica varias técnicas sofisticadas, desde la generación de texto a audio hasta la síntesis de voz avanzada, pasando por el análisis y la recombinación de patrones musicales existentes.

Suno AI es una plataforma de creación musical con inteligencia artificial generativa, diseñada para permitir a los usuarios generar canciones realistas que incorporan tanto voz como instrumentación basadas en indicaciones de texto. El proceso comienza con una descripción textual del tema deseado: género musical, atmósfera, temas líricos, instrumentación preferida. El algoritmo analiza estas entradas y genera una composición completa que incluye melodías, armonías, ritmos y, cuando se solicita, letras e interpretaciones vocales.

La tecnología subyacente se basa en redes neuronales profundas entrenadas en enormes bases de datos musicales. Suno se diferencia de otros generadores de música de IA porque puede crear canciones completas con canto, letra e incluso una portada para el álbum. Este entrenamiento permite a la IA reconocer patrones musicales, estructuras compositivas y convenciones estilísticas típicas de diferentes géneros musicales, para luego recombinarlas de formas nuevas y creativamente interesantes.

Un aspecto particularmente avanzado es la capacidad de generar interpretaciones vocales convincentes. La síntesis de voz utilizada en estos sistemas va mucho más allá de la simple conversión de texto a voz. Los algoritmos son capaces de interpretar el contenido emocional de las letras y de modular en consecuencia el timbre, la entonación, la dinámica y la articulación vocal. El resultado son interpretaciones que transmiten emociones y matices expresivos comparables a los de los cantantes humanos.

Una función avanzada permite a los usuarios tomar sonidos del mundo real —como ruido ambiental, palabras habladas o ritmos sencillos— y transformarlos en composiciones musicales completas. Esta funcionalidad abre posibilidades creativas inéditas, permitiendo transformar cualquier entrada sonora en material musical estructurado.

Sin embargo, es importante subrayar que detrás de cada tema generado por la IA siempre hay un elemento de "dirección creativa humana". En el caso de The Velvet Sundown e Iam, los resultados finales son fruto de un proceso iterativo en el que los operadores humanos guían a la IA a través de indicaciones cada vez más específicas, seleccionan los mejores resultados y a menudo los procesan posteriormente a través de software de producción musical tradicional.

Esto plantea una cuestión fundamental: ¿cuánto de "artificial" tiene realmente esta música? El proceso creativo, aunque mediado por la tecnología, mantiene elementos de intuición, gusto y elección artística típicamente humanos. Los creadores de estos proyectos describen su papel como el de "directores creativos" que utilizan la IA como una herramienta, aunque muy avanzada, para hacer realidad sus visiones artísticas.

Las limitaciones actuales de la tecnología siguen siendo evidentes en varios ámbitos. La coherencia narrativa en los textos largos, la capacidad de crear progresiones musicales complejas y la interpretación de matices culturales específicos siguen representando retos importantes. Sin embargo, la evolución es rapidísima: a finales de 2024, Suno lanzó una campaña promocional con Timbaland, uno de los productores de hip hop más influyentes, lo que indica un creciente reconocimiento por parte de la industria musical profesional.

## Las reacciones del sector: voces del mundo de la música

La aparición de proyectos como The Velvet Sundown e Iam ha desatado reacciones contrapuestas en el seno de la industria musical, revelando profundas divisiones entre quienes ven en la IA una oportunidad revolucionaria y quienes la consideran una amenaza existencial para el arte musical.

Las reacciones de los artistas se han polarizado en líneas previsibles pero no por ello menos significativas. Músicos y creativos argumentan que la música creada por la IA carece de los elementos esenciales de la creatividad humana, como la emoción, la experiencia vivida y el contexto cultural. El compositor ganador de un Grammy, Hans Zimmer, que ha experimentado con música asistida por IA, sostiene que la IA no puede replicar la profundidad emocional que se deriva de la experiencia humana directa.

En el otro extremo del espectro, un número creciente de artistas está adoptando estas tecnologías como herramientas creativas. Algunos músicos emergentes han comenzado a utilizar la IA como colaborador creativo, generando ideas iniciales que luego desarrollan y refinan a través de procesos tradicionales. Este enfoque híbrido está creando un nuevo paradigma creativo que combina la eficiencia algorítmica con la intuición artística humana.

Las plataformas de streaming se enfrentan a retos inéditos. Spotify, Apple Music y otras grandes empresas del sector deben desarrollar políticas para gestionar los contenidos generados por la IA, equilibrando la innovación tecnológica con la protección de los intereses de los artistas tradicionales. Algunas plataformas están experimentando con etiquetados específicos para los contenidos generados por IA, mientras que otras prefieren mantener un enfoque neutral, dejando que sea el mercado quien decida.

Cientos de artistas han firmado una carta abierta en la que advierten contra el uso "depredador" de la IA en la música, pidiendo a las empresas tecnológicas que no utilicen la inteligencia artificial para violar los derechos de los artistas humanos. Esta iniciativa, promovida por la Artist Rights Alliance, pone de manifiesto la creciente preocupación por el impacto económico de la IA en la comunidad artística.

El público, por su parte, muestra reacciones complejas y a menudo contradictorias. Mientras que muchos oyentes aprecian la música de IA cuando no conocen su origen, la revelación de su naturaleza artificial suele llevar a una reevaluación crítica. Sin embargo, una parte creciente del público, especialmente entre las generaciones más jóvenes, muestra una mayor apertura hacia la innovación tecnológica en el ámbito artístico.

Los críticos musicales se encuentran en una posición especialmente delicada. ¿Cómo evaluar artísticamente un tema que no nace de la creatividad humana tradicional? ¿Qué criterios utilizar para juzgar la autenticidad y el valor estético de la música generada algorítmicamente? Algunas publicaciones especializadas han comenzado a desarrollar nuevos marcos críticos específicamente pensados para la era de la música de IA.

Los expertos en marketing de la industria musical identifican tres conclusiones principales: el uso ético de la música generada por IA es escalable, nos encontramos en el "Salvaje Oeste" de esta tecnología donde las decisiones que se tomen ahora determinarán los precedentes para el futuro, y crear música con IA puede ser divertido. Esta perspectiva pragmática pone de manifiesto cómo el sector se está adaptando gradualmente a la nueva realidad tecnológica.

## La dimensión ética: autenticidad, derechos y creatividad

Las implicaciones éticas de la música de IA plantean cuestiones fundamentales que van al corazón mismo de la creatividad artística y de la industria del entretenimiento. El caso de The Velvet Sundown, con su estrategia inicial de ocultar el origen artificial de la música, ha puesto de manifiesto el problema de la transparencia hacia el público. ¿Es ético permitir que los oyentes desarrollen conexiones emocionales con la música artificial sin que sean conscientes de ello?

La cuestión plantea interrogantes sobre la autenticidad de la forma de arte. Algunos argumentan que la música generada por la IA carece de la profundidad emocional y la expresión personal que posee la música creada por los humanos. Esta postura, aunque comprensible, abre a su vez interrogantes más profundos: ¿qué define la autenticidad en una época en la que la mayor parte de la música comercial ya está fuertemente mediada por la tecnología?

El concepto de creatividad se encuentra en el centro del debate ético. ¿Es la creatividad una prerrogativa exclusivamente humana o puede ser replicada e incluso superada por sistemas artificiales? Proyectos como Iam y The Velvet Sundown sugieren que la IA puede producir resultados creativos que resuenan emocionalmente con el público, independientemente de su origen no humano. Esto podría indicar que la creatividad es más un proceso de recombinación innovadora de elementos existentes que una misteriosa chispa divina exclusivamente humana.

Las cuestiones de copyright y derechos de autor representan un terreno minado legal y ético. Los desarrolladores de música de IA deben dar prioridad a prácticas de licencia éticas y colaborar estrechamente con compositores y propietarios de derechos de autor. Pero, ¿cómo se definen los derechos sobre la música generada por algoritmos entrenados con millones de temas existentes? ¿Quién posee los derechos de autor de una canción de IA: el programador del algoritmo, el usuario que proporcionó la indicación o nadie?

Una decisión de un tribunal estadounidense ha establecido que las composiciones totalmente generadas por IA —donde un artista simplemente pulsa un botón y deja que la IA cree una canción de principio a fin— no pueden estar protegidas por derechos de autor. Esto sitúa los temas puramente generados por IA en el dominio público, haciéndolos libremente disponibles para su uso o reproducción por parte de cualquiera. La distinción crucial es el nivel de aportación humana: la Oficina de Derechos de Autor de los Estados Unidos ha establecido que "el toque humano marca la diferencia", pero hay distinciones importantes que considerar.

Tennessee ha aprobado la Ley ELVIS (Ensuring Likeness Voice and Image Security Act), la primera ley estadounidense que protege a los músicos del uso no autorizado de la inteligencia artificial, actualizando la ley de Protección de los Derechos Personales del estado para incluir protecciones para la voz y la imagen. Una vez que la ley entró en vigor el 1 de julio de 2024, estará prohibido utilizar la IA para imitar la voz de un artista sin permiso. Pero la tecnología, hábil en la copia de voces y estilos de artistas reales, se mueve demasiado rápido como para que una sola ley pueda seguirle el ritmo. Esta carrera entre la innovación tecnológica y la regulación legal pone de manifiesto la necesidad de marcos éticos y legales más ágiles y adaptables.

El impacto sobre los músicos profesionales es quizás el aspecto ético más inmediato y concreto. La investigación identifica dos cuestiones urgentes: el inevitable aumento de la población artística excedentaria y la disminución del coste del trabajo creativo. Si la IA puede producir música de calidad comercial a costes marginales, ¿cuál será el futuro económico de los músicos, compositores y productores?

Sin embargo, no todos los escenarios son necesariamente negativos. Algunos expertos proponen un modelo de colaboración hombre-máquina en el que la IA amplifica las capacidades creativas humanas en lugar de sustituirlas. En este escenario, los músicos podrían utilizar la IA para explorar nuevas direcciones creativas, superar bloqueos compositivos o realizar proyectos que de otro modo requerirían recursos prohibitivos.

Organizaciones como Sound Ethics están "abrazando la IA en la industria musical protegiendo y apoyando a los artistas, asegurando nuestras carreras futuras. A través de asociaciones con instituciones educativas, expertos legales y partes interesadas, estamos estableciendo nuevos estándares y promoviendo políticas que protejan los derechos de los artistas".

La democratización de la creación musical presenta tanto oportunidades como riesgos éticos. Por un lado, la IA puede permitir a personas sin formación musical formal expresar su creatividad y llegar a un público global. Por otro, esta facilidad de acceso podría llevar a una saturación del mercado musical con contenidos de calidad variable, haciendo aún más difícil que los artistas emergentes destaquen.

La cuestión de la diversidad cultural es igualmente compleja. Los algoritmos de música de IA se entrenan principalmente con música comercial occidental, con el riesgo de perpetuar sesgos culturales y de homogeneizar la expresión musical global. ¿Cómo garantizar que la IA no se convierta en un instrumento de estandarización cultural, sino que mantenga y celebre la diversidad de las tradiciones musicales del mundo?

## Escenarios futuros: hacia dónde va la música de IA

La evolución tecnológica en el campo de la música de IA avanza a un ritmo acelerado, lo que sugiere escenarios futuros que podrían transformar radicalmente la industria del entretenimiento en los próximos años. Las previsiones de los expertos del sector dibujan posibilidades tan fascinantes como inquietantes para el futuro de la creación musical.

Desde un punto de vista puramente tecnológico, las mejoras esperadas son significativas. Para 2026-2027, es probable que veamos sistemas de música de IA capaces de crear composiciones de larga duración manteniendo la coherencia narrativa y el desarrollo temático. La integración con tecnologías de realidad virtual y aumentada podría permitir experiencias musicales inmersivas en las que la IA genere bandas sonoras en tiempo real basándose en las emociones y los comportamientos del usuario.

La reciente evolución de Suno, con asociaciones con productores de primer nivel como Timbaland, sugiere una transición de una herramienta para aficionados a una plataforma profesional. Esta tendencia podría llevar a la aparición de nuevas figuras profesionales: los "directores creativos de IA" que se especializan en la guía algorítmica para producciones musicales comerciales.

El escenario optimista prevé la IA como un amplificador de la creatividad humana. En esta visión, músicos y productores utilizarán la inteligencia artificial como un colaborador inagotable, capaz de sugerir infinitas variaciones, explorar territorios sonoros inexplorados y realizar arreglos complejos en tiempo récord. Pequeños sellos discográficos podrían competir con las grandes discográficas gracias a la democratización de las herramientas de producción. Artistas independientes podrían crear álbumes completos con presupuestos limitados, centrándose en la visión creativa mientras la IA gestiona los aspectos técnicos más complejos.

En este escenario positivo, surgiría una nueva economía creativa en la que el valor se desplaza de la capacidad técnica a la visión artística y la capacidad de conexión emocional con el público. Los artistas humanos podrían especializarse en actuaciones en directo, narrativas conceptuales y experiencias artísticas que la IA no puede replicar, mientras que la inteligencia artificial gestiona la producción en masa y la creación de contenidos personalizados.

Sin embargo, el escenario pesimista presenta riesgos considerables. La facilidad de producción podría llevar a una saturación del mercado musical con contenidos algorítmicos de calidad media, haciendo cada vez más difícil para los artistas humanos destacar y mantener la sostenibilidad económica. La estandarización algorítmica podría homogeneizar los gustos musicales, reduciendo la diversidad estilística y cultural que siempre ha caracterizado al arte musical.

Un riesgo particular lo representa la posible pérdida de conexión entre el artista y el público. Si la música se convierte principalmente en un producto algorítmico optimizado para la máxima participación, podríamos perder esa dimensión de vulnerabilidad y autenticidad humana que siempre ha constituido el corazón de la experiencia musical. La música podría pasar de ser una forma de expresión artística a un producto de consumo optimizado para algoritmos de recomendación.

La cuestión de la regulación será crucial. Será necesario desarrollar marcos legales que equilibren la innovación tecnológica con la protección de los derechos de los artistas y la transparencia hacia los consumidores. Algunos países podrían exigir el etiquetado obligatorio de los contenidos generados por IA, mientras que otros podrían adoptar enfoques más liberales. En los Estados Unidos, se ha propuesto la Ley de Divulgación de Derechos de Autor de la IA Generativa de 2024, que exigiría a las empresas que desarrollan IA generativa que revelen los conjuntos de datos utilizados para el entrenamiento. Los sellos discográficos que tienen contratos con artistas podrían emprender acciones legales contra las partes que infrinjan los derechos, aunque estos remedios están actualmente limitados geográficamente.

La educación musical tendrá que evolucionar necesariamente. Las escuelas de música y los conservatorios tendrán que integrar la IA en sus planes de estudio, enseñando a los estudiantes no solo a tocar instrumentos y componer, sino también a colaborar eficazmente con sistemas inteligentes. Surgirán nuevas disciplinas como la "dirección creativa algorítmica" y la "ingeniería de la experiencia musical de IA".

El modelo de negocio de la industria musical sufrirá profundas transformaciones. Podrían surgir servicios de "música a la carta" en los que los usuarios encarguen temas personalizados para ocasiones específicas. Las playlists podrían convertirse en composiciones algorítmicas en tiempo real, adaptándose dinámicamente al estado de ánimo y a las actividades del oyente.

## Conclusiones: la inevitabilidad del cambio

El análisis de los casos de The Velvet Sundown e Iam revela que la integración de la inteligencia artificial en la música ya no es una perspectiva de futuro, sino una realidad presente que ya está redefiniendo los paradigmas creativos y comerciales de la industria. Estos proyectos pioneros han demostrado que la IA puede producir música no solo técnicamente competente, sino también emocionalmente atractiva y comercialmente viable.

La verdadera lección que se desprende de esta revolución silenciosa es que el valor de la música no reside exclusivamente en su origen humano, sino en su capacidad para conectar con la experiencia emocional de los oyentes. The Velvet Sundown conquistó a medio millón de oyentes mensuales antes de que nadie descubriera su naturaleza artificial. Iam ha generado apasionados debates en los medios de comunicación italianos no solo como una curiosidad tecnológica, sino como un auténtico fenómeno artístico.

Sin embargo, esta transformación plantea cuestiones éticas que requieren respuestas meditadas. La transparencia hacia el público, la protección de los derechos de los artistas humanos, la preservación de la diversidad cultural y la sostenibilidad económica del sector musical son retos que requieren el compromiso coordinado de tecnólogos, artistas, reguladores y sociedad civil.

La evolución en curso sugiere que el futuro de la música no será necesariamente una sustitución de lo humano por lo artificial, sino más bien una rearticulación de los roles creativos en la que la inteligencia humana y la artificial colaboren de formas nuevas e inéditas. Los artistas del futuro puede que no sean sustituidos por la IA, pero tendrán que aprender a trabajar con ella, utilizándola como una herramienta para amplificar sus propias capacidades creativas.

La democratización de la creación musical que ofrece la IA presenta oportunidades extraordinarias para la expresión creativa, permitiendo a personas sin formación musical formal dar vida a sus propias visiones artísticas. Al mismo tiempo, esta accesibilidad exige nuevos criterios para evaluar la calidad y la originalidad en un mundo en el que cualquiera puede producir música profesional con unos pocos clics.

El cambio es inevitable, pero su dirección no está predeterminada. Las decisiones que tomemos hoy —como sociedad, como industria, como consumidores— determinarán si la música de IA se convertirá en un instrumento de liberación creativa o de estandarización comercial, si ampliará la diversidad artística o la reducirá, si apoyará a los artistas humanos o los sustituirá.

La historia de The Velvet Sundown e Iam no ha hecho más que empezar. Representan los primeros capítulos de una transformación que seguirá evolucionando en los próximos años, desafiando nuestras concepciones de creatividad, autenticidad y valor artístico. Su éxito nos recuerda que, en última instancia, la música que importa es la que consigue tocar el alma humana, independientemente de su origen. El reto para el futuro será garantizar que esta capacidad de conexión emocional no se pierda en la transición a la era de la música con inteligencia artificial.

Mientras tanto, los "cimientos de los derechos de autor en la música tal como la conocemos" siguen viéndose sacudidos por la rápida evolución de la IA, en un momento en que la industria musical se encuentra en el centro del debate sobre la propiedad intelectual a nivel mundial. La partida no ha hecho más que empezar, y las reglas del juego aún se están definiendo.

## Resurrección digital: hacer cantar a los que ya no están

Dado el tema, me ha parecido oportuno ponerlo después de las conclusiones, imagino que entenderéis el irónico porqué. Me gustaría, en efecto, hablaros de la última "frontera" de la inteligencia artificial musical: hacer "resucitar" digitalmente a artistas fallecidos hace décadas para hacerles cantar nuevas canciones.

El caso estalló hace solo unos días, cuando una canción titulada "Together" apareció en la página oficial de Spotify de Blaze Foley, cantautor de country asesinado en 1989, seguida de "Happened To You", atribuida a Guy Clark, ganador de un Grammy fallecido en 2016.

Los temas, marcados con el copyright de una misteriosa "Syntax Error" y subidos a través de la plataforma SoundOn de TikTok sin la autorización de los herederos o las discográficas, desataron una feroz polémica antes de ser retirados.

Craig McDonald, propietario del sello que gestiona el catálogo de Foley, descubrió casualmente la publicación no autorizada, lo que plantea inquietantes interrogantes sobre los límites éticos de esta tecnología.

Si ya discutimos sobre transparencia y autenticidad con artistas de IA "vivos y coleando", imaginad las implicaciones cuando se trata de hacer cantar a los muertos sin su consentimiento. Evidentemente, en la era de la inteligencia artificial, ni siquiera la muerte representa ya un límite para la carrera discográfica.

Pero esa es otra historia que merecería un artículo aparte, quizás titulado "Cuando la IA se encuentra con el más allá: guía práctica de la nigromancia digital".
